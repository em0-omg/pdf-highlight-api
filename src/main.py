from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pdf2image import convert_from_bytes
import uvicorn
import io
import base64
import os
import re
from src.infrastructure.gemini import GeminiImageAnalyzer

app = FastAPI(
    title="å›³é¢PDFè§£æAPI",
    version="0.2.0",
    description="å›³é¢PDFã‚’åˆ†æã—ã€PF100/PF150ã®æ–‡è¨€ã¨ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ç‰¹åŒ–å‹API",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gemini API Key ã®çŠ¶æ…‹ã‚’ç¢ºèª
gemini_api_key = os.getenv("GEMINI_API_KEY")
gemini_analyzer = None
gemini_available = False

if gemini_api_key:
    try:
        gemini_analyzer = GeminiImageAnalyzer()
        gemini_available = True
        print("âœ… Gemini API Key found. Analysis features are available.")
    except Exception as e:
        print(f"âŒ Error initializing Gemini: {e}")
        print("ğŸ”§ Please check your GEMINI_API_KEY.")
else:
    print("âš ï¸  GEMINI_API_KEY not found.")
    print("ğŸ”§ Please set GEMINI_API_KEY in your .env file to enable analysis features.")
    print("ğŸ“ Get your API key from: https://makersuite.google.com/app/apikey")


@app.get("/")
async def hello_world():
    return {
        "message": "å›³é¢PDFè§£æAPI is running",
        "description": "å›³é¢PDFã‚’åˆ†æã—ã€PF100/PF150ã®æ–‡è¨€ã¨ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹ç‰¹åŒ–å‹API",
        "gemini_available": gemini_available,
        "status": "âœ… Ready" if gemini_available else "âš ï¸ Gemini API Key required",
        "setup_help": (
            "Set GEMINI_API_KEY in .env file" if not gemini_available else None
        ),
        "features": [
            "PF100/PF150æ–‡è¨€æ¤œå‡º",
            "è¨˜å·ä½ç½®åº§æ¨™æ¤œå‡º",
            "è‡ªå‹•ã‚«ã‚¦ãƒ³ãƒˆ",
            "ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º",
        ],
    }


@app.post("/analyze-pdf")
async def analyze_pdf(
    file: UploadFile = File(...),
    dpi: int = 200,
    highlight: bool = Query(True, description="ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã©ã†ã‹"),
    prompt: str = Query(
        "ã“ã®å›³é¢ä¸Šã§ã€ŒPF100Ï†ã€ã¨ã€ŒPF150Ï†ã€ã®æ–‡è¨€ã‚’ç‰¹å®šã—ã€æ­£ç¢ºã«ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„ã€‚\n"
        "ä»–ã®è¨˜å·ã‚„æ–‡å­—ã¯ç„¡è¦–ã—ã€PF100Ï†ã€PF150Ï†ã®ã¿ã«ç‰¹åŒ–ã—ã¦æ¤œå‡ºã—ã¦ãã ã•ã„ã€‚\n"
        "æ¤œå‡ºçµæœã¯ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š\n"
        "- PF100Ï†: Xç®‡æ‰€\n"
        "- PF150Ï†: Yç®‡æ‰€",
        description="PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
    ),
):
    """
    å›³é¢PDFãƒ•ã‚¡ã‚¤ãƒ«ã§PF100Ï†/PF150Ï†æ–‡è¨€ã‚’æ¤œå‡ºã—ã€ã‚«ã‚¦ãƒ³ãƒˆãƒ»åº§æ¨™å–å¾—ã‚’å®Ÿè¡Œã™ã‚‹

    Parameters:
    - file: PDFãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰
    - dpi: ç”»åƒå¤‰æ›è§£åƒåº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ200ï¼‰
    - highlight: ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½æœ‰åŠ¹åŒ–ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrueï¼‰
    - prompt: PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºç‰¹åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

    Returns:
    - PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºçµæœ
    - æ­£ç¢ºãªã‚«ã‚¦ãƒ³ãƒˆæ•°ã¨åº§æ¨™æƒ…å ±
    - ãƒã‚¤ãƒ©ã‚¤ãƒˆä»˜ãç”»åƒï¼ˆhighlight=Trueã®å ´åˆï¼‰
    """
    print(f"ğŸ“„ PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºé–‹å§‹: {file.filename}")

    if not gemini_available:
        print("âŒ Gemini APIä¸å¯: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        raise HTTPException(
            status_code=503,
            detail="Gemini analysis service is not available. Please set GEMINI_API_KEY in your .env file. Get your API key from: https://makersuite.google.com/app/apikey",
        )

    if not file.filename or not file.filename.endswith(".pdf"):
        print(f"âŒ ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: {file.filename}")
        raise HTTPException(status_code=400, detail="Only PDF files are allowed")

    try:
        print("ğŸ“– PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        pdf_bytes = await file.read()

        print(f"ğŸ–¼ï¸  PDFã‚’ç”»åƒã«å¤‰æ›ä¸­... (DPI: {dpi})")
        images = convert_from_bytes(pdf_bytes, dpi=dpi)
        print(f"âœ… å¤‰æ›å®Œäº†: {len(images)}ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’ç”Ÿæˆ")

        # ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        print("ğŸ¨ å…ƒç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...")
        preview_images = _create_image_previews(images)
        print("âœ… å…ƒç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†")

        # åº§æ¨™æ¤œå‡ºã¨ãƒã‚¤ãƒ©ã‚¤ãƒˆå‡¦ç†
        highlighted_images = []
        all_detection_data = []

        if highlight:
            print("ğŸ¯ PF100Ï†/PF150Ï†æ–‡è¨€åº§æ¨™æ¤œå‡ºã‚’é–‹å§‹...")
            for i, image in enumerate(images):
                print(f"ğŸ“ ãƒšãƒ¼ã‚¸{i+1}: PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºä¸­...")
                if gemini_analyzer:
                    detection_data = (
                        await gemini_analyzer.analyze_image_with_coordinates(
                            image, ["PF100Ï†", "PF150Ï†"]
                        )
                    )
                    all_detection_data.append(detection_data)

                    if "error" not in detection_data:
                        print(f"ğŸ¨ ãƒšãƒ¼ã‚¸{i+1}: ãƒã‚¤ãƒ©ã‚¤ãƒˆæç”»ä¸­...")
                        highlighted_image = gemini_analyzer.create_highlighted_image(
                            image, detection_data
                        )

                        # ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¸ˆã¿ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                        img_buffer = io.BytesIO()
                        highlighted_image.save(img_buffer, format="PNG")
                        img_buffer.seek(0)
                        img_base64 = base64.b64encode(img_buffer.getvalue()).decode(
                            "utf-8"
                        )

                        highlighted_images.append(
                            {
                                "page": i + 1,
                                "image_data": f"data:image/png;base64,{img_base64}",
                                "detections": detection_data.get("detections", []),
                                "summary": detection_data.get("summary", {}),
                            }
                        )
                        print(f"âœ… ãƒšãƒ¼ã‚¸{i+1}: ãƒã‚¤ãƒ©ã‚¤ãƒˆå®Œäº†")
                    else:
                        print(
                            f"âš ï¸ ãƒšãƒ¼ã‚¸{i+1}: åº§æ¨™æ¤œå‡ºã‚¨ãƒ©ãƒ¼ - {detection_data.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                        )
                        highlighted_images.append(
                            {
                                "page": i + 1,
                                "error": detection_data.get(
                                    "error", "åº§æ¨™æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"
                                ),
                            }
                        )
                else:
                    print(f"âš ï¸ ãƒšãƒ¼ã‚¸{i+1}: Geminiåˆ†ææ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“")
                    highlighted_images.append(
                        {"page": i + 1, "error": "Geminiåˆ†ææ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“"}
                    )
            print("âœ… å…¨ãƒšãƒ¼ã‚¸ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆå‡¦ç†å®Œäº†")

        # PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºåˆ†æã‚’å®Ÿè¡Œ
        print("ğŸ¤– PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºåˆ†æã‚’é–‹å§‹...")
        if gemini_analyzer:
            if len(images) > 1:
                print(
                    f"ğŸ“š è¤‡æ•°ãƒšãƒ¼ã‚¸åˆ†æ: {len(images)}ãƒšãƒ¼ã‚¸ã§PF100Ï†/PF150Ï†æ–‡è¨€ã‚’æ¤œå‡ºä¸­..."
                )
                analysis_results = await gemini_analyzer.analyze_images(images, prompt)
                overall_analysis = (
                    f"å…¨{len(images)}ãƒšãƒ¼ã‚¸ã®PF100Ï†/PF150Ï†æ¤œå‡ºçµæœ:\n"
                    + "\n\n".join(
                        [
                            f"ãƒšãƒ¼ã‚¸{i+1}: {result}"
                            for i, result in enumerate(analysis_results)
                        ]
                    )
                )
                print("âœ… è¤‡æ•°ãƒšãƒ¼ã‚¸PF100Ï†/PF150Ï†æ¤œå‡ºå®Œäº†")
            else:
                print("ğŸ“„ å˜ä¸€ãƒšãƒ¼ã‚¸PF100Ï†/PF150Ï†æ¤œå‡ºä¸­...")
                overall_analysis = await gemini_analyzer.analyze_image(
                    images[0], prompt
                )
                print("âœ… å˜ä¸€ãƒšãƒ¼ã‚¸PF100Ï†/PF150Ï†æ¤œå‡ºå®Œäº†")
        else:
            overall_analysis = "Geminiåˆ†ææ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"

        # PF100Ï†/PF150Ï†ã®ã‚«ã‚¦ãƒ³ãƒˆçµæœã‚’æŠ½å‡ºï¼ˆåº§æ¨™ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’çµ±åˆï¼‰
        pf_counts = _extract_pf_counts(overall_analysis)

        # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰PF100Ï†/PF150Ï†ã®æ­£ç¢ºãªã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—
        if all_detection_data:
            coordinate_counts = {"PF100Ï†": 0, "PF150Ï†": 0, "total_detections": 0}
            for detection_data in all_detection_data:
                if "summary" in detection_data:
                    coordinate_counts["PF100Ï†"] += detection_data["summary"].get(
                        "pf100_count", 0
                    )
                    coordinate_counts["PF150Ï†"] += detection_data["summary"].get(
                        "pf150_count", 0
                    )
                    coordinate_counts["total_detections"] += detection_data[
                        "summary"
                    ].get("total_detections", 0)

            # åº§æ¨™ãƒ™ãƒ¼ã‚¹ã®PF100Ï†/PF150Ï†ã‚«ã‚¦ãƒ³ãƒˆã‚’ãƒ¡ã‚¤ãƒ³ã«ä½¿ç”¨
            pf_counts["coordinate_based"] = coordinate_counts

        print(f"ğŸ‰ PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºå®Œäº†: {file.filename}")

        response_data = {
            "filename": file.filename,
            "total_pages": len(images),
            "analysis": overall_analysis,
            "pf_counts": pf_counts,
            "images": preview_images,
            "prompt": prompt,
            "dpi": dpi,
            "highlight_enabled": highlight,
            "analysis_type": "PF100Ï†/PF150Ï†æ–‡è¨€æ¤œå‡ºç‰¹åŒ–å‹API",
        }

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿è¿½åŠ 
        if highlight:
            response_data["highlighted_images"] = highlighted_images
            response_data["detection_data"] = all_detection_data

        return response_data

    except Exception as e:
        print(f"âŒ PDFå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error processing PDF: {str(e)}")


def _create_image_previews(images: list) -> list:
    """
    ç”»åƒã®Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆ
    """
    preview_images = []
    for i, image in enumerate(images):
        img_buffer = io.BytesIO()
        image.save(img_buffer, format="PNG")
        img_buffer.seek(0)

        img_base64 = base64.b64encode(img_buffer.getvalue()).decode("utf-8")
        preview_images.append(
            {"page": i + 1, "image_data": f"data:image/png;base64,{img_base64}"}
        )

    return preview_images


def _extract_pf_counts(analysis_text: str) -> dict:
    """
    AIåˆ†æçµæœã‹ã‚‰PF100Ï†ã¨PF150Ï†ã®ã‚«ã‚¦ãƒ³ãƒˆæ•°ã‚’æŠ½å‡º
    """
    pf_counts = {
        "PF100Ï†": 0,
        "PF150Ï†": 0,
        "extraction_details": {"found_pf100_patterns": [], "found_pf150_patterns": []},
    }

    try:
        # PF100Ï†ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        pf100_patterns = [
            r"PF100Ï†[:\s]*(\d+)[ç®‡å€‹ãƒ¶]æ‰€",
            r"PF100Î¦[:\s]*(\d+)[ç®‡å€‹ãƒ¶]æ‰€",
            r"PF100Ï†[:\s]*(\d+)ç®‡æ‰€",
            r"PF100Î¦[:\s]*(\d+)ç®‡æ‰€",
            r"PF100Ï†[:\s]*(\d+)å€‹",
            r"PF100Î¦[:\s]*(\d+)å€‹",
            r"PF100Ï†[:\s]*(\d+)ãƒ¶æ‰€",
            r"PF100Î¦[:\s]*(\d+)ãƒ¶æ‰€",
            r"PF100Ï†[:\s]*(\d+)\s*ç®‡æ‰€",
            r"PF100Î¦[:\s]*(\d+)\s*ç®‡æ‰€",
            r"ã€Œ?PF100Ï†ã€?[:\s]*(\d+)",
            r"ã€Œ?PF100Î¦ã€?[:\s]*(\d+)",
            r"PF100Ï†.*?(\d+)ç®‡æ‰€",
            r"PF100Î¦.*?(\d+)ç®‡æ‰€",
            r"PF100Ï†.*?(\d+)å€‹æ‰€",
            r"PF100Î¦.*?(\d+)å€‹æ‰€",
        ]

        # PF150Ï†ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢
        pf150_patterns = [
            r"PF150Ï†[:\s]*(\d+)[ç®‡å€‹ãƒ¶]æ‰€",
            r"PF150Î¦[:\s]*(\d+)[ç®‡å€‹ãƒ¶]æ‰€",
            r"PF150Ï†[:\s]*(\d+)ç®‡æ‰€",
            r"PF150Î¦[:\s]*(\d+)ç®‡æ‰€",
            r"PF150Ï†[:\s]*(\d+)å€‹",
            r"PF150Î¦[:\s]*(\d+)å€‹",
            r"PF150Ï†[:\s]*(\d+)ãƒ¶æ‰€",
            r"PF150Î¦[:\s]*(\d+)ãƒ¶æ‰€",
            r"PF150Ï†[:\s]*(\d+)\s*ç®‡æ‰€",
            r"PF150Î¦[:\s]*(\d+)\s*ç®‡æ‰€",
            r"ã€Œ?PF150Ï†ã€?[:\s]*(\d+)",
            r"ã€Œ?PF150Î¦ã€?[:\s]*(\d+)",
            r"PF150Ï†.*?(\d+)ç®‡æ‰€",
            r"PF150Î¦.*?(\d+)ç®‡æ‰€",
            r"PF150Ï†.*?(\d+)å€‹æ‰€",
            r"PF150Î¦.*?(\d+)å€‹æ‰€",
        ]

        # PF100Ï†ã‚’æ¤œç´¢
        for pattern in pf100_patterns:
            matches = re.findall(pattern, analysis_text, re.IGNORECASE)
            if matches:
                pf_counts["PF100Ï†"] = int(matches[0])
                extraction_details = pf_counts.get("extraction_details")
                if isinstance(extraction_details, dict):
                    extraction_details["found_pf100_patterns"].append(
                        {"pattern": pattern, "count": int(matches[0])}
                    )
                break

        # PF150Ï†ã‚’æ¤œç´¢
        for pattern in pf150_patterns:
            matches = re.findall(pattern, analysis_text, re.IGNORECASE)
            if matches:
                pf_counts["PF150Ï†"] = int(matches[0])
                extraction_details = pf_counts.get("extraction_details")
                if isinstance(extraction_details, dict):
                    extraction_details["found_pf150_patterns"].append(
                        {"pattern": pattern, "count": int(matches[0])}
                    )
                break

        # å˜ç´”ãªæ–‡å­—åˆ—æ¤œç´¢ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦å®Ÿè¡Œï¼ˆPF100Ï†/PF150Ï†ã®ã¿ï¼‰
        if pf_counts["PF100Ï†"] == 0:
            pf100_mentions = len(re.findall(r"PF100[Ï†Î¦]", analysis_text, re.IGNORECASE))
            if pf100_mentions > 0:
                extraction_details = pf_counts.get("extraction_details")
                if isinstance(extraction_details, dict):
                    extraction_details["found_pf100_patterns"].append(
                        {
                            "pattern": "simple_pf100phi_mention_count",
                            "count": pf100_mentions,
                        }
                    )

        if pf_counts["PF150Ï†"] == 0:
            pf150_mentions = len(re.findall(r"PF150[Ï†Î¦]", analysis_text, re.IGNORECASE))
            if pf150_mentions > 0:
                extraction_details = pf_counts.get("extraction_details")
                if isinstance(extraction_details, dict):
                    extraction_details["found_pf150_patterns"].append(
                        {
                            "pattern": "simple_pf150phi_mention_count",
                            "count": pf150_mentions,
                        }
                    )

    except Exception as e:
        print(f"âš ï¸ PF100Ï†/PF150Ï†ã‚«ã‚¦ãƒ³ãƒˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        pf_counts["extraction_error"] = str(e)

    return pf_counts


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
